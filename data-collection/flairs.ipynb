{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "c7283f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2996, 7)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libs\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Read in csv for all universities\n",
    "df = pd.read_csv('all_posts.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c422a7",
   "metadata": {},
   "source": [
    "Social media tends to have a lot of memes/non-sensical discussion. For this project it would be valuable to filter out these types of posts and focus on posts that are more likely to have criticisms about the university."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "06cf5d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Transfers', 'Discussion', 'Humour', 'Serious', 'News', 'Other',\n",
       "       'Rant', 'Health', 'Clubs/Sports', 'Social', 'Event', 'Courses',\n",
       "       'Waterloo #173', 'Academics', 'Advice', 'Confirmed', 'Meta', nan,\n",
       "       'Shitpost', 'Lost & Found', 'Question', 'Politics', 'Life Advice',\n",
       "       'Admissions', 'Finances', 'Programs', 'ACORN/Quercus/Outlook',\n",
       "       'Free Speech', 'Waterloo #201‚Äì250', 'UTM/UTSC',\n",
       "       \"I'm in High School\", 'Jobs', 'Photography & Art',\n",
       "       'Pho(ur seasons)tography & Art', '@ SFU (Exception)', 'Megathread',\n",
       "       'Congrats, you made it!', 'Photography &amp; Art',\n",
       "       'Humour - Satire', 'SFU = Studying For UBC', 'Prose', 'üçÅ',\n",
       "       '100% super duper confirmed by the r/byssey', 'üî•üî•üî•',\n",
       "       'Ghost-type Humour', 'Unverified', 'Lost Dog', 'üéâüéâüéâ',\n",
       "       'Read Comments Section for full context', 'Missing Person', 'F',\n",
       "       'Spicy', 'HQ Post', 'Spicy Meme', 'We did it, reddit!',\n",
       "       'HQ shitpost', 'Certified Dank', 'shitpost', 'Political',\n",
       "       'I should be working rn', 'MEGATHREAD', 'University Politics',\n",
       "       'TW: sexual violence', 'From Laurier University', 'TW: Suicide',\n",
       "       'Martlet Club', 'coronavirus', 'HQ Shitpost', 'Wholesome Post',\n",
       "       'artsy shitpost', 'SSMU', 'megathread', 'Resolved! ',\n",
       "       'TW: sexual harrassment', 'Stay Home', 'Funny/Meme'], dtype=object)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Want to see post flairs, and subsequently filter for non-shitposts\n",
    "df['flair'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b812338a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flair\n",
       "Humour               961\n",
       "Discussion           223\n",
       "Other                159\n",
       "Photography & Art    116\n",
       "shitpost              73\n",
       "News                  49\n",
       "Academics             28\n",
       "Advice                22\n",
       "Courses               22\n",
       "HQ Post               21\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most popular flairs\n",
    "df['flair'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "1ab0ee6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1485, 7)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter for popular/relevant flairs\n",
    "df = df[df['flair'].isin(['Humour', 'Discussion', 'Other', 'News', 'Academics', 'Advice', 'Courses', 'HQ Post'])]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860d7c10",
   "metadata": {},
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "977dbecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_created</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>comments</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>flair</th>\n",
       "      <th>university</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-02-12 18:36:14</td>\n",
       "      <td>To the student who got caught using AI on their exam at U of T Law</td>\n",
       "      <td>Thanks a lot you dumb f*ck. Due to your idiocy and dumbassery my college (not in Ontario) is now...</td>\n",
       "      <td>['[deleted]', 'It‚Äôs crazy that there‚Äôs people mad at YOU for venting.', 'Gaining access to your ...</td>\n",
       "      <td>2942</td>\n",
       "      <td>Transfers</td>\n",
       "      <td>UofT</td>\n",
       "      <td>to the student who got caught using ai on their exam at uoft law thanks a lot you dumb f*ck. due...</td>\n",
       "      <td>[student, got, caught, using, ai, exam, uoft, law, thanks, lot, dumb, f, ck, due, idiocy, dumbas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-08 03:24:09</td>\n",
       "      <td>[ Removed by Reddit ]</td>\n",
       "      <td>[ Removed by Reddit on account of violating the [content policy](/help/contentpolicy). ]</td>\n",
       "      <td>['Ik this man, he‚Äôs getting cooked. Maybe uoft won‚Äôt do anything but it‚Äôs over for him and his s...</td>\n",
       "      <td>2939</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>UofT</td>\n",
       "      <td>['ik this man, he‚Äôs getting cooked. maybe uoft won‚Äôt do anything but it‚Äôs over for him and his s...</td>\n",
       "      <td>[man, getting, cooked, maybe, uoft, anything, social, life, esp, w, apparently, deleted, twitter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-13 19:48:06</td>\n",
       "      <td>I want a ps5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['i LOVE  how low effort this looks', 'pain', 'loool u made my day..', 'Those boys and scalpers ...</td>\n",
       "      <td>2749</td>\n",
       "      <td>Humour</td>\n",
       "      <td>UofT</td>\n",
       "      <td>i want a ps5  ['i love  how low effort this looks', 'pain', 'loool u made my day..', 'those boys...</td>\n",
       "      <td>[want, love, low, effort, look, u, made, day, boy, scalper, really, took, thing, quick, shopper,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-12-14 00:38:33</td>\n",
       "      <td>If this thread gets over 300 upvotes in the next 24h I will change the sub to r/idealcatering un...</td>\n",
       "      <td>srsly don't fuck this up for me, we're already working on the css don't want this shit to go to ...</td>\n",
       "      <td>['[deleted]', '[deleted]', \"Found this in /r/all/rising, I'll give my updoot.\", \"/r/uwaterloo's ...</td>\n",
       "      <td>2485</td>\n",
       "      <td>Serious</td>\n",
       "      <td>UofT</td>\n",
       "      <td>if this thread gets over 300 upvotes in the next 24h i will change the sub to r/idealcatering un...</td>\n",
       "      <td>[thread, get, upvotes, next, change, sub, exam, srsly, fuck, already, working, cs, want, shit, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-05-14 00:11:02</td>\n",
       "      <td>University of Toronto Faculty Association votes to divest from Israel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Big W, honestly im surprised', 'W faculty', 'Honestly amazing to hear!', 'Proud of my alma mat...</td>\n",
       "      <td>2163</td>\n",
       "      <td>News</td>\n",
       "      <td>UofT</td>\n",
       "      <td>uoft faculty association votes to divest from israel  ['big w, honestly im surprised', 'w facult...</td>\n",
       "      <td>[uoft, faculty, association, vote, divest, israel, w, honestly, im, surprised, w, faculty, amazi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date_created  \\\n",
       "0  2025-02-12 18:36:14   \n",
       "1  2024-11-08 03:24:09   \n",
       "2  2020-11-13 19:48:06   \n",
       "3  2016-12-14 00:38:33   \n",
       "4  2025-05-14 00:11:02   \n",
       "\n",
       "                                                                                                 title  \\\n",
       "0                                   To the student who got caught using AI on their exam at U of T Law   \n",
       "1                                                                                [ Removed by Reddit ]   \n",
       "2                                                                                         I want a ps5   \n",
       "3  If this thread gets over 300 upvotes in the next 24h I will change the sub to r/idealcatering un...   \n",
       "4                                University of Toronto Faculty Association votes to divest from Israel   \n",
       "\n",
       "                                                                                           description  \\\n",
       "0  Thanks a lot you dumb f*ck. Due to your idiocy and dumbassery my college (not in Ontario) is now...   \n",
       "1             [ Removed by Reddit on account of violating the [content policy](/help/contentpolicy). ]   \n",
       "2                                                                                                  NaN   \n",
       "3  srsly don't fuck this up for me, we're already working on the css don't want this shit to go to ...   \n",
       "4                                                                                                  NaN   \n",
       "\n",
       "                                                                                              comments  \\\n",
       "0  ['[deleted]', 'It‚Äôs crazy that there‚Äôs people mad at YOU for venting.', 'Gaining access to your ...   \n",
       "1  ['Ik this man, he‚Äôs getting cooked. Maybe uoft won‚Äôt do anything but it‚Äôs over for him and his s...   \n",
       "2  ['i LOVE  how low effort this looks', 'pain', 'loool u made my day..', 'Those boys and scalpers ...   \n",
       "3  ['[deleted]', '[deleted]', \"Found this in /r/all/rising, I'll give my updoot.\", \"/r/uwaterloo's ...   \n",
       "4  ['Big W, honestly im surprised', 'W faculty', 'Honestly amazing to hear!', 'Proud of my alma mat...   \n",
       "\n",
       "   upvotes       flair university  \\\n",
       "0     2942   Transfers       UofT   \n",
       "1     2939  Discussion       UofT   \n",
       "2     2749      Humour       UofT   \n",
       "3     2485     Serious       UofT   \n",
       "4     2163        News       UofT   \n",
       "\n",
       "                                                                                         combined_text  \\\n",
       "0  to the student who got caught using ai on their exam at uoft law thanks a lot you dumb f*ck. due...   \n",
       "1  ['ik this man, he‚Äôs getting cooked. maybe uoft won‚Äôt do anything but it‚Äôs over for him and his s...   \n",
       "2  i want a ps5  ['i love  how low effort this looks', 'pain', 'loool u made my day..', 'those boys...   \n",
       "3  if this thread gets over 300 upvotes in the next 24h i will change the sub to r/idealcatering un...   \n",
       "4  uoft faculty association votes to divest from israel  ['big w, honestly im surprised', 'w facult...   \n",
       "\n",
       "                                                                                     lemmatized_tokens  \n",
       "0  [student, got, caught, using, ai, exam, uoft, law, thanks, lot, dumb, f, ck, due, idiocy, dumbas...  \n",
       "1  [man, getting, cooked, maybe, uoft, anything, social, life, esp, w, apparently, deleted, twitter...  \n",
       "2  [want, love, low, effort, look, u, made, day, boy, scalper, really, took, thing, quick, shopper,...  \n",
       "3  [thread, get, upvotes, next, change, sub, exam, srsly, fuck, already, working, cs, want, shit, g...  \n",
       "4  [uoft, faculty, association, vote, divest, israel, w, honestly, im, surprised, w, faculty, amazi...  "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Init stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def clean_text(df):\n",
    "    '''\n",
    "    This function does 3 things\n",
    "\n",
    "    1. Combines text from title, description and comments\n",
    "    2. Normalizes university names\n",
    "    3. Tokenizes and lemmatizes text and removes stopwords + reddit specific words\n",
    "\n",
    "    '''\n",
    "    remove_words = ['removed', 'deleted', '[ removed by reddit ]', '[deleted]']\n",
    "    # custom_stopwords = {'student', 'course', 'people', 'get', 'like', 'time', 'year', 'would'}\n",
    "    # Combine text from title, description and comments\n",
    "    def combine_text(text): \n",
    "\n",
    "        if isinstance(text, list):\n",
    "            return ' '.join([word for word in text if isinstance(word, str) and word.lower() not in remove_words])\n",
    "        elif isinstance(text, str): \n",
    "            # Filter out posts removed by reddit\n",
    "            if re.search(r\"\\[?\\s*removed by reddit.*?\\]?\", text, flags=re.IGNORECASE):\n",
    "                return ''\n",
    "            return text\n",
    "        return ''\n",
    "\n",
    "    \n",
    "    \n",
    "    # Normalize university names\n",
    "    def normalize_university(text):\n",
    "        # Regex to normalize uni names\n",
    "        text = re.sub(r'u\\sof\\st', 'uoft', text)\n",
    "        text = re.sub(r'university of toronto', 'uoft', text)\n",
    "        text = re.sub(r'university of british columbia', 'ubc', text)\n",
    "        return text\n",
    "\n",
    "    # Tokenize + lematize + remove stopwords\n",
    "    def tokenize_and_lemmatize(text): \n",
    "\n",
    "        # Tokenize\n",
    "        tokens = word_tokenize(text)\n",
    "\n",
    "        # Filter for strings\n",
    "        words = [word for word in tokens if word.isalpha()]\n",
    "\n",
    "        # Remove stopwords\n",
    "        words = [word for word in words if word not in stop_words]\n",
    "        \n",
    "        # Lemmatize\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        return [lemmatizer.lemmatize(word) for word in words]\n",
    "    \n",
    "    # Combine text\n",
    "    df['combined_text'] = (df['title'].apply(combine_text).fillna('') + ' ' +\n",
    "                       df['description'].apply(combine_text).fillna('') + ' ' +\n",
    "                       df['comments'].apply(combine_text))\n",
    "\n",
    "    # Lower + removing trailing charsa\n",
    "    df['combined_text'] = df['combined_text'].str.lower().str.strip()\n",
    "    \n",
    "    # Normalize university names\n",
    "    df['combined_text'] = df['combined_text'].apply(normalize_university)\n",
    "\n",
    "    # Tokenize + lemmatize\n",
    "    df['lemmatized_tokens'] = df['combined_text'].apply(tokenize_and_lemmatize)\n",
    "\n",
    "    # Return cleaned df\n",
    "    return df\n",
    "\n",
    "df = clean_text(df)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51a48a2",
   "metadata": {},
   "source": [
    "## Investigating top k words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "82ff2688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---All Posts---\n",
      "[('people', 15312), ('like', 14454), ('student', 13110), ('get', 11587), ('year', 9617), ('one', 9602), ('would', 9429), ('time', 8748), ('think', 8472), ('know', 7732)]\n",
      "---Transfers---\n",
      "[('ai', 60), ('college', 52), ('lawyer', 34), ('use', 32), ('law', 30), ('school', 28), ('university', 28), ('student', 26), ('using', 21), ('people', 21)]\n",
      "---Discussion---\n",
      "[('people', 3817), ('like', 3058), ('student', 2560), ('get', 2262), ('would', 1921), ('one', 1875), ('year', 1851), ('think', 1815), ('time', 1560), ('know', 1559)]\n",
      "---Humour---\n",
      "[('like', 2250), ('get', 1882), ('year', 1841), ('people', 1606), ('one', 1567), ('student', 1558), ('course', 1456), ('time', 1429), ('would', 1160), ('class', 1133)]\n",
      "---Serious---\n",
      "[('http', 21), ('deleted', 16), ('get', 12), ('goose', 11), ('meme', 10), ('u', 10), ('post', 9), ('hour', 9), ('uoft', 9), ('upvotes', 8)]\n",
      "---News---\n",
      "[('people', 699), ('student', 545), ('like', 378), ('get', 358), ('would', 343), ('one', 328), ('think', 313), ('uoft', 269), ('know', 269), ('http', 267)]\n",
      "---Other---\n",
      "[('like', 749), ('people', 556), ('year', 533), ('one', 527), ('get', 517), ('student', 495), ('would', 456), ('think', 436), ('time', 433), ('uoft', 362)]\n",
      "---Rant---\n",
      "[('uoft', 293), ('student', 240), ('like', 196), ('university', 171), ('get', 153), ('school', 136), ('people', 134), ('year', 126), ('would', 113), ('one', 112)]\n",
      "---Health---\n",
      "[('people', 213), ('removed', 188), ('like', 148), ('get', 138), ('time', 115), ('think', 101), ('mask', 100), ('one', 99), ('know', 99), ('year', 87)]\n",
      "---Clubs/Sports---\n",
      "[('walk', 34), ('bike', 27), ('keyboard', 19), ('next', 18), ('like', 17), ('student', 15), ('love', 14), ('bikechain', 14), ('http', 14), ('get', 13)]\n",
      "---Social---\n",
      "[('student', 118), ('english', 76), ('international', 66), ('people', 35), ('class', 34), ('uoft', 33), ('language', 30), ('canadian', 30), ('even', 29), ('like', 27)]\n",
      "---Event---\n",
      "[('people', 74), ('like', 57), ('chalkboard', 43), ('board', 32), ('ukrainian', 32), ('one', 30), ('get', 29), ('ukraine', 28), ('rally', 26), ('would', 25)]\n",
      "---Courses---\n",
      "[('course', 336), ('student', 262), ('like', 218), ('class', 211), ('time', 149), ('one', 145), ('year', 144), ('prof', 143), ('would', 137), ('get', 133)]\n",
      "---Waterloo #173---\n",
      "[('post', 19), ('tattoo', 13), ('get', 10), ('http', 9), ('goose', 8), ('stupid', 8), ('meme', 7), ('truck', 7), ('food', 6), ('updoots', 6)]\n",
      "---Academics---\n",
      "[('student', 374), ('course', 234), ('exam', 194), ('get', 181), ('people', 172), ('like', 161), ('prof', 161), ('one', 143), ('would', 138), ('time', 129)]\n",
      "---Advice---\n",
      "[('year', 765), ('time', 598), ('get', 465), ('people', 402), ('like', 397), ('course', 369), ('take', 328), ('student', 326), ('would', 324), ('work', 319)]\n",
      "---Confirmed---\n",
      "[('police', 13), ('like', 10), ('guy', 9), ('hope', 9), ('asian', 9), ('caught', 8), ('got', 8), ('report', 7), ('deleted', 7), ('shit', 7)]\n",
      "---Meta---\n",
      "[('http', 83), ('uoft', 53), ('chinese', 49), ('subreddit', 46), ('post', 43), ('people', 40), ('student', 38), ('deleted', 38), ('kong', 35), ('would', 33)]\n",
      "---nan---\n",
      "[]\n",
      "---Shitpost---\n",
      "[('guy', 25), ('bucket', 23), ('like', 23), ('shit', 22), ('shall', 16), ('people', 15), ('man', 15), ('uoft', 15), ('someone', 14), ('would', 13)]\n",
      "---Lost & Found---\n",
      "[('back', 8), ('person', 4), ('get', 4), ('bro', 4), ('got', 4), ('ear', 4), ('week', 4), ('put', 3), ('address', 3), ('find', 3)]\n",
      "---Question---\n",
      "[('ci', 261), ('people', 144), ('like', 101), ('student', 82), ('go', 79), ('know', 79), ('year', 77), ('would', 76), ('say', 74), ('one', 74)]\n",
      "---Politics---\n",
      "[('student', 25), ('like', 21), ('online', 20), ('class', 17), ('instructor', 16), ('uoft', 13), ('university', 13), ('people', 11), ('take', 11), ('school', 11)]\n",
      "---Life Advice---\n",
      "[('year', 15), ('proud', 8), ('u', 7), ('took', 5), ('graduate', 5), ('major', 5), ('back', 5), ('much', 5), ('congrats', 5), ('got', 5)]\n",
      "---Admissions---\n",
      "[('got', 337), ('offer', 326), ('get', 305), ('admission', 300), ('round', 295), ('uoft', 246), ('application', 210), ('c', 203), ('still', 192), ('know', 185)]\n",
      "---Finances---\n",
      "[('student', 109), ('get', 70), ('year', 51), ('income', 49), ('job', 47), ('deleted', 47), ('make', 45), ('month', 44), ('still', 42), ('benefit', 42)]\n",
      "---Programs---\n",
      "[('black', 53), ('course', 44), ('people', 42), ('student', 22), ('like', 21), ('would', 18), ('class', 15), ('point', 14), ('white', 14), ('right', 14)]\n",
      "---ACORN/Quercus/Outlook---\n",
      "[('schedule', 22), ('year', 19), ('timetable', 14), ('like', 13), ('one', 13), ('course', 12), ('good', 11), ('na', 10), ('gon', 9), ('colour', 9)]\n",
      "---Free Speech---\n",
      "[('people', 55), ('http', 39), ('think', 26), ('deleted', 26), ('like', 25), ('speech', 22), ('would', 22), ('student', 19), ('see', 18), ('peterson', 17)]\n",
      "---Waterloo #201‚Äì250---\n",
      "[('cobra', 4), ('chicken', 4), ('e', 4), ('uwaterloo', 2), ('agent', 2), ('back', 2), ('never', 2), ('power', 2), ('ranking', 2), ('meme', 2)]\n",
      "---UTM/UTSC---\n",
      "[('bad', 4), ('look', 3), ('u', 3), ('danny', 2), ('utm', 2), ('panam', 2), ('know', 2), ('deleted', 2), ('comment', 2), ('cuz', 2)]\n",
      "---I'm in High School---\n",
      "[('get', 22), ('school', 18), ('high', 17), ('student', 12), ('c', 11), ('good', 11), ('would', 10), ('applying', 9), ('year', 9), ('got', 9)]\n",
      "---Jobs---\n",
      "[('job', 16), ('application', 12), ('gpa', 10), ('even', 9), ('cr', 9), ('get', 8), ('one', 8), ('cover', 8), ('letter', 8), ('like', 8)]\n",
      "---Photography & Art---\n",
      "[('ubc', 189), ('like', 174), ('year', 161), ('http', 151), ('time', 141), ('get', 139), ('one', 133), ('campus', 131), ('see', 124), ('good', 118)]\n",
      "---Pho(ur seasons)tography & Art---\n",
      "[('miss', 4), ('season', 3), ('picture', 3), ('walking', 2), ('school', 2), ('one', 2), ('left', 2), ('accurate', 2), ('got', 2), ('ubc', 2)]\n",
      "---@ SFU (Exception)---\n",
      "[('myanmar', 7), ('post', 7), ('ubc', 6), ('student', 6), ('hope', 5), ('piazza', 4), ('get', 4), ('deleted', 4), ('situation', 4), ('country', 3)]\n",
      "---Megathread---\n",
      "[('course', 316), ('year', 316), ('student', 289), ('get', 259), ('people', 240), ('ubc', 235), ('would', 225), ('like', 206), ('science', 201), ('got', 180)]\n",
      "---Congrats, you made it!---\n",
      "[('grade', 2), ('class', 2), ('average', 2), ('acted', 2), ('integrity', 2), ('deleted', 2), ('gotten', 2), ('even', 2), ('get', 2), ('cpen', 2)]\n",
      "---Photography &amp; Art---\n",
      "[('ubc', 5), ('national', 3), ('royale', 2), ('uni', 2), ('ranked', 2), ('u', 2), ('remain', 2), ('open', 2), ('world', 2), ('emergency', 2)]\n",
      "---Humour - Satire---\n",
      "[('mask', 12), ('deleted', 6), ('u', 5), ('wear', 4), ('http', 4), ('first', 3), ('know', 3), ('„ÉÑ', 3), ('important', 3), ('gon', 2)]\n",
      "---SFU = Studying For UBC---\n",
      "[('ndp', 14), ('vote', 10), ('riding', 9), ('voting', 9), ('ubc', 7), ('liberal', 5), ('conservative', 5), ('sfu', 4), ('look', 4), ('see', 4)]\n",
      "---Prose---\n",
      "[('ubc', 15), ('year', 14), ('school', 14), ('like', 11), ('beautiful', 11), ('place', 10), ('life', 10), ('feel', 9), ('experience', 9), ('goldenrod', 8)]\n",
      "---üçÅ---\n",
      "[('canada', 7), ('le', 3), ('canadian', 3), ('vive', 3), ('gooo', 2), ('mile', 2), ('go', 2), ('take', 2), ('game', 2), ('territory', 2)]\n",
      "---100% super duper confirmed by the r/byssey---\n",
      "[('joke', 10), ('april', 8), ('year', 6), ('mean', 5), ('fool', 4), ('day', 4), ('deleted', 4), ('people', 3), ('going', 3), ('think', 3)]\n",
      "---üî•üî•üî•---\n",
      "[('proctorio', 41), ('student', 41), ('exam', 26), ('academic', 26), ('faculty', 20), ('concern', 16), ('undergraduate', 14), ('society', 14), ('ubc', 14), ('vp', 14)]\n",
      "---Ghost-type Humour---\n",
      "[('cube', 3), ('place', 3), ('know', 3), ('go', 3), ('wooden', 2), ('always', 2), ('people', 2), ('pretty', 2), ('great', 2), ('inside', 2)]\n",
      "---Unverified---\n",
      "[('people', 58), ('like', 24), ('athlete', 23), ('ubc', 21), ('party', 21), ('team', 21), ('year', 20), ('variant', 19), ('think', 19), ('get', 18)]\n",
      "---Lost Dog---\n",
      "[('dog', 17), ('missing', 12), ('find', 10), ('continue', 10), ('ubc', 9), ('please', 9), ('search', 9), ('thank', 8), ('hope', 8), ('tofino', 7)]\n",
      "---üéâüéâüéâ---\n",
      "[('exam', 15), ('course', 6), ('student', 6), ('prof', 6), ('everyone', 5), ('class', 5), ('good', 5), ('one', 5), ('luck', 5), ('like', 5)]\n",
      "---Read Comments Section for full context---\n",
      "[('deleted', 23), ('proctorio', 21), ('student', 12), ('make', 10), ('get', 10), ('minute', 10), ('roy', 9), ('op', 9), ('like', 9), ('company', 9)]\n",
      "---Missing Person---\n",
      "[('hope', 4), ('find', 3), ('people', 3), ('friend', 3), ('soon', 3), ('pretty', 2), ('hiking', 2), ('season', 2), ('missing', 2), ('please', 2)]\n",
      "---F---\n",
      "[('f', 135), ('gerts', 12), ('year', 8), ('deleted', 7), ('next', 4), ('got', 4), ('day', 3), ('bit', 3), ('lost', 3), ('bda', 3)]\n",
      "---Spicy---\n",
      "[('indigenous', 68), ('people', 54), ('student', 48), ('admission', 34), ('ubc', 32), ('get', 32), ('person', 27), ('someone', 26), ('lower', 25), ('comment', 24)]\n",
      "---HQ Post---\n",
      "[('people', 121), ('like', 79), ('time', 62), ('mcgill', 61), ('would', 59), ('year', 57), ('know', 55), ('one', 55), ('building', 52), ('also', 51)]\n",
      "---Spicy Meme---\n",
      "[('turn', 4), ('camera', 3), ('mic', 3), ('zoom', 3), ('important', 2), ('take', 2), ('bathroom', 2), ('mode', 2), ('everyone', 2), ('went', 2)]\n",
      "---We did it, reddit!---\n",
      "[('community', 2), ('number', 2), ('accomplished', 1), ('burnside', 1), ('thank', 1), ('much', 1), ('whole', 1), ('making', 1), ('possible', 1), ('people', 1)]\n",
      "---HQ shitpost---\n",
      "[('squirrel', 6), ('ragan', 6), ('one', 5), ('shitpost', 4), ('final', 4), ('deleted', 3), ('back', 3), ('year', 3), ('actually', 3), ('thing', 3)]\n",
      "---Certified Dank---\n",
      "[('http', 4), ('content', 2), ('mb', 2), ('many', 1), ('assignment', 1), ('right', 1), ('subreddit', 1), ('keep', 1), ('getting', 1), ('better', 1)]\n",
      "---shitpost---\n",
      "[('like', 93), ('mcgill', 88), ('people', 82), ('student', 75), ('get', 71), ('class', 65), ('one', 57), ('think', 56), ('know', 54), ('deleted', 53)]\n",
      "---Political---\n",
      "[('people', 281), ('mcgill', 209), ('protest', 177), ('think', 158), ('like', 141), ('student', 129), ('israel', 125), ('encampment', 119), ('one', 113), ('would', 112)]\n",
      "---I should be working rn---\n",
      "[('posture', 4), ('like', 3), ('bad', 3), ('feel', 2), ('attacked', 2), ('smh', 2), ('back', 2), ('check', 1), ('pic', 1), ('picture', 1)]\n",
      "---MEGATHREAD---\n",
      "[('ssmu', 143), ('student', 122), ('people', 110), ('mcgill', 93), ('israel', 93), ('palestinian', 90), ('exam', 87), ('would', 78), ('like', 78), ('right', 72)]\n",
      "---University Politics---\n",
      "[('student', 82), ('ssmu', 57), ('benefit', 42), ('bar', 41), ('like', 41), ('people', 41), ('gerts', 35), ('mcgill', 32), ('right', 29), ('think', 29)]\n",
      "---TW: sexual violence---\n",
      "[('mcgill', 30), ('people', 20), ('sexual', 17), ('assault', 15), ('campus', 15), ('victim', 15), ('think', 13), ('student', 13), ('like', 12), ('really', 12)]\n",
      "---From Laurier University---\n",
      "[('student', 12), ('prof', 11), ('like', 9), ('cheat', 9), ('class', 7), ('cheating', 6), ('report', 5), ('people', 5), ('pretty', 5), ('mcgill', 5)]\n",
      "---TW: Suicide---\n",
      "[('mcgill', 12), ('need', 11), ('mental', 10), ('health', 10), ('help', 10), ('feel', 10), ('like', 10), ('time', 9), ('please', 8), ('reach', 8)]\n",
      "---Martlet Club---\n",
      "[('people', 46), ('virus', 33), ('chinese', 25), ('comment', 25), ('deleted', 19), ('post', 14), ('say', 14), ('china', 13), ('speech', 12), ('bad', 12)]\n",
      "---coronavirus---\n",
      "[('covid', 13), ('people', 11), ('mcgill', 10), ('know', 9), ('number', 7), ('test', 7), ('get', 6), ('think', 6), ('like', 6), ('immunity', 6)]\n",
      "---HQ Shitpost---\n",
      "[('prof', 9), ('lecture', 7), ('video', 6), ('like', 6), ('really', 5), ('one', 5), ('experience', 4), ('people', 4), ('kinda', 4), ('started', 4)]\n",
      "---Wholesome Post---\n",
      "[('cloudberry', 6), ('boy', 4), ('cute', 3), ('look', 3), ('like', 2), ('squirrel', 2), ('best', 2), ('lesser', 1), ('known', 1), ('brother', 1)]\n",
      "---artsy shitpost---\n",
      "[('mcgill', 4), ('polisci', 3), ('see', 3), ('chaotic', 2), ('like', 2), ('concordia', 2), ('look', 2), ('people', 2), ('work', 2), ('btw', 2)]\n",
      "---SSMU---\n",
      "[('ssmu', 11), ('email', 10), ('holiday', 8), ('remembrance', 6), ('day', 6), ('country', 6), ('sent', 5), ('like', 5), ('even', 5), ('mcgill', 5)]\n",
      "---megathread---\n",
      "[('would', 31), ('people', 28), ('online', 24), ('get', 22), ('day', 20), ('measure', 18), ('curfew', 18), ('school', 17), ('like', 17), ('covid', 16)]\n",
      "---Resolved! ---\n",
      "[('da', 16), ('back', 7), ('red', 6), ('reddit', 6), ('blue', 4), ('guess', 4), ('who', 4), ('please', 3), ('use', 3), ('white', 3)]\n",
      "---TW: sexual harrassment---\n",
      "[('feel', 18), ('get', 13), ('would', 11), ('mcgill', 10), ('help', 10), ('like', 10), ('report', 9), ('sorry', 9), ('people', 9), ('apartment', 8)]\n",
      "---Stay Home---\n",
      "[('mcgill', 105), ('student', 100), ('class', 94), ('online', 85), ('know', 85), ('http', 83), ('week', 74), ('like', 67), ('time', 60), ('going', 60)]\n",
      "---Funny/Meme---\n",
      "[('think', 13), ('something', 12), ('people', 11), ('said', 9), ('class', 8), ('like', 8), ('girl', 8), ('american', 8), ('comment', 8), ('person', 8)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_topk_words(df, k):\n",
    "    '''\n",
    "    Takes a df and returns top k words from tokens\n",
    "    '''\n",
    "    all_tokens = [token for row in df['lemmatized_tokens'] for token in row]\n",
    "\n",
    "    # Count frequencies\n",
    "    token_counts = Counter(all_tokens)\n",
    "\n",
    "    # Get top K words\n",
    "    top_k = token_counts.most_common(k)\n",
    "\n",
    "    return top_k\n",
    "\n",
    "# Get top 10 most common words across all posts\n",
    "print(f'---All Posts---\\n{get_topk_words(df, 10)}')\n",
    "\n",
    "# Get top 10 most common words across flairs\n",
    "for flair in df['flair'].unique():\n",
    "    print(f'---{flair}---\\n{get_topk_words(df[df['flair'] == flair], 10)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8b3da5",
   "metadata": {},
   "source": [
    "It seems all posts feature words that are probably common throughout each flair."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666f45da",
   "metadata": {},
   "source": [
    "Mutual Information (MI). If we treat our flair as a rough topic label, we can use MI to tell us information that is shared in the non-linear relationships between tokens and flairs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9190a281",
   "metadata": {},
   "source": [
    "### Preparing df for MI calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "28269221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 500 most common words across all universities\n",
    "top_500 = get_topk_words(df, 500)\n",
    "\n",
    "# 500 most common words for each university\n",
    "uoft_df = df[df['university'] == 'UofT']\n",
    "ubc_df = df[df['university'] == 'UBC']\n",
    "mcgill_df = df[df['university'] == 'McGill']\n",
    "\n",
    "uoft_500 = get_topk_words(uoft_df, 500)\n",
    "ubc_500 = get_topk_words(ubc_df, 500)\n",
    "mcgill_500 = get_topk_words(mcgill_df, 500)\n",
    "\n",
    "# Convert words to bool columns for MI\n",
    "def create_mi_df(df):\n",
    "\n",
    "    # Get top k words\n",
    "    top_500 = get_topk_words(df, 500)\n",
    "\n",
    "    # Save flair column\n",
    "    mi_df = df[['flair']].copy()\n",
    "\n",
    "    # Convert words to bool columns\n",
    "    binary_columns = []\n",
    "    \n",
    "    for word, _ in top_500:\n",
    "        binary_series = df['lemmatized_tokens'].apply(lambda tokens: int(word in tokens))\n",
    "        binary_series.name = word\n",
    "        binary_columns.append(binary_series)\n",
    "\n",
    "    # Concatenate all columns at once\n",
    "    binary_df = pd.concat(binary_columns, axis=1)\n",
    "\n",
    "    # Combine with the flair column\n",
    "    mi_df = pd.concat([mi_df, binary_df], axis=1)\n",
    "\n",
    "    return mi_df\n",
    "\n",
    "# Get MI ready df for all + each university\n",
    "all_mi = create_mi_df(df)\n",
    "uoft_mi = create_mi_df(uoft_df)\n",
    "ubc_mi = create_mi_df(ubc_df)\n",
    "mcgill_mi = create_mi_df(mcgill_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b19d1f",
   "metadata": {},
   "source": [
    "### Making getMI function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "61f7cf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "def getMI(df, label_column = 'flair'):\n",
    "\n",
    "    # Get list of topk words from MI df\n",
    "    topk = df.select_dtypes(include = np.number).columns\n",
    "\n",
    "    # Get label column names\n",
    "    unique_labels = df[label_column].unique()\n",
    "\n",
    "    all_scores = []\n",
    "\n",
    "    for flair in unique_labels:\n",
    "        label = (df[label_column] == flair).astype(int)\n",
    "\n",
    "        # Get MI for topk words in flair\n",
    "        for word in topk:\n",
    "            score = mutual_info_score(label, df[word])\n",
    "            all_scores.append({'word': word, 'mi': score, 'flair': flair})\n",
    "\n",
    "    return pd.DataFrame(all_scores).sort_values(by='mi', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "c7c39a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mi_scores = getMI(all_mi)\n",
    "uoft_mi_scores = getMI(uoft_mi)\n",
    "ubc_mi_scores = getMI(ubc_mi)\n",
    "mcgill_mi_scores = getMI(mcgill_mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "2ed28012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>mi</th>\n",
       "      <th>flair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>mcgill</td>\n",
       "      <td>0.068635</td>\n",
       "      <td>Humour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>hope</td>\n",
       "      <td>0.026098</td>\n",
       "      <td>Humour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>else</td>\n",
       "      <td>0.022138</td>\n",
       "      <td>Discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>lot</td>\n",
       "      <td>0.022100</td>\n",
       "      <td>Discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2543</th>\n",
       "      <td>uoft</td>\n",
       "      <td>0.021509</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>health</td>\n",
       "      <td>0.020930</td>\n",
       "      <td>Humour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>around</td>\n",
       "      <td>0.020727</td>\n",
       "      <td>Humour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>campus</td>\n",
       "      <td>0.020607</td>\n",
       "      <td>Humour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>montreal</td>\n",
       "      <td>0.020460</td>\n",
       "      <td>Humour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>time</td>\n",
       "      <td>0.020138</td>\n",
       "      <td>Discussion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word        mi       flair\n",
       "1040    mcgill  0.068635      Humour\n",
       "1099      hope  0.026098      Humour\n",
       "647       else  0.022138  Discussion\n",
       "547        lot  0.022100  Discussion\n",
       "2543      uoft  0.021509       Other\n",
       "1152    health  0.020930      Humour\n",
       "1082    around  0.020727      Humour\n",
       "1075    campus  0.020607      Humour\n",
       "1455  montreal  0.020460      Humour\n",
       "507       time  0.020138  Discussion"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mi_scores.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0709eef6",
   "metadata": {},
   "source": [
    "Noticing that words with highest MI seem to be just the most common words... Will see what normalizing for word frequency does."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4412e3",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "bedba697",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "def evalsentences(sentences, universities, to_df = False, columns = []):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    pdlist = []\n",
    "\n",
    "    if to_df:\n",
    "        # Maintain index from original df\n",
    "        for i, sentence in (sentences.items() if isinstance(sentences, pd.Series) else enumerate(sentences)):\n",
    "            ss = sid.polarity_scores(sentence)\n",
    "            row = [sentence, ss['compound']]\n",
    "            if universities is not None:\n",
    "                uni_val = universities.loc[i] if isinstance(universities, pd.Series) else universities[i]\n",
    "                row.append(uni_val)\n",
    "            pdlist.append((i, row))\n",
    "        \n",
    "        # Build into df\n",
    "        df = pd.DataFrame([row for _, row in pdlist],\n",
    "                          index=[idx for idx, _ in pdlist],\n",
    "                          columns=columns)\n",
    "        return df\n",
    "    \n",
    "    else:\n",
    "        for sentrence in sentences:\n",
    "            print('\\n' + sentence)\n",
    "            ss = sid.polarity_scores(sentence)\n",
    "            for k in sorted(ss):\n",
    "                print('{0}: {1}, '.format(k, ss[k], end = ''))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4892a476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Distribution of VADER sentiment scores across posts')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comments = df['combined_text']\n",
    "universities = df['university']\n",
    "vader_df = evalsentences(comments, universities, to_df = True, columns = ['comments', 'vader', 'university_name'])\n",
    "\n",
    "# See distribution of sentiment across posts\n",
    "sns.histplot(vader_df['vader'])\n",
    "plt.title('Distribution of VADER sentiment scores across posts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "7354ed01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flair\n",
       "News          0.45\n",
       "Humour        0.23\n",
       "Discussion    0.22\n",
       "Academics     0.18\n",
       "Other         0.18\n",
       "Advice        0.14\n",
       "HQ Post       0.14\n",
       "Courses       0.05\n",
       "Name: is_neg, dtype: float64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set option to show longer comments\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "# Add flair back in\n",
    "vader_df['flair'] = df['flair']\n",
    "\n",
    "# See what percent of comments are rated negative from VADER by flair\n",
    "vader_df['is_neg'] = vader_df['vader'] < 0\n",
    "\n",
    "percent_neg = (vader_df.groupby('flair')['is_neg']\n",
    "               .mean()\n",
    "               .round(2) \n",
    "               ).sort_values(ascending = False)\n",
    "\n",
    "percent_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0213c2d4",
   "metadata": {},
   "source": [
    "## PMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e33cddef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def calcpmi(df, topk_words, gt_sentiment, label_column, smoothing = 1):\n",
    "\n",
    "    # Number of observations\n",
    "    n = len(df)\n",
    "    label_mask = df[label_column] == gt_sentiment\n",
    "\n",
    "    pmi_scores = []\n",
    "\n",
    "    # Add smoothing to avoid log(0)\n",
    "    px = label_mask.sum() + smoothing\n",
    "\n",
    "    # Math for pmi\n",
    "    for word, _ in topk_words:\n",
    "\n",
    "        word_mask = df[word] == True\n",
    "\n",
    "        py = word_mask.sum() + smoothing\n",
    "\n",
    "        pxy = (label_mask & word_mask).sum() + smoothing\n",
    "\n",
    "        pmi = np.log((pxy * n) / (px*py))\n",
    "\n",
    "        pmi_scores.append((word, pmi))\n",
    "    \n",
    "    return pd.DataFrame(pmi_scores, columns = ['word', 'pmi']).set_index('word')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0d824d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmi</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>university</th>\n",
       "      <td>7.303170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>israel</th>\n",
       "      <td>4.412798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pharmacy</th>\n",
       "      <td>4.084294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roommate</th>\n",
       "      <td>3.837434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indigenous</th>\n",
       "      <td>3.806662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wage</th>\n",
       "      <td>3.614291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vaccine</th>\n",
       "      <td>3.589598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>protest</th>\n",
       "      <td>3.589598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>china</th>\n",
       "      <td>3.295837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mask</th>\n",
       "      <td>3.225633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pmi\n",
       "word                \n",
       "university  7.303170\n",
       "israel      4.412798\n",
       "pharmacy    4.084294\n",
       "roommate    3.837434\n",
       "indigenous  3.806662\n",
       "wage        3.614291\n",
       "vaccine     3.589598\n",
       "protest     3.589598\n",
       "china       3.295837\n",
       "mask        3.225633"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pmi df\n",
    "pmi_df = pd.concat([mi_df, vader_df[['is_neg', 'university_name']]], axis = 1)\n",
    "\n",
    "# Get top pmi for words and negative sentiment across all posts\n",
    "calcpmi(pmi_df, top_500, 'negative', 'is_neg').sort_values(by = 'pmi', ascending= False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a518633",
   "metadata": {},
   "source": [
    "### Investigating words associated with negative sentiment by flair at each uni"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97eedfb",
   "metadata": {},
   "source": [
    "UofT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "0eb28d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Discussion-------\n",
      "                  pmi\n",
      "word                 \n",
      "roommate     3.850148\n",
      "genocide     3.444682\n",
      "hamas        2.933857\n",
      "palestinian  2.751535\n",
      "cheating     2.597385\n",
      "israel       2.597385\n",
      "pharmacy     2.597385\n",
      "vaccine      2.597385\n",
      "schedule     2.463853\n",
      "letter       2.463853\n",
      "------Humour-------\n",
      "                  pmi\n",
      "word                 \n",
      "hamas        6.236370\n",
      "israel       6.236370\n",
      "palestinian  6.236370\n",
      "genocide     4.850075\n",
      "pharmacy     4.626932\n",
      "protest      4.626932\n",
      "roommate     4.290459\n",
      "vaccine      4.156928\n",
      "police       4.039145\n",
      "war          3.933784\n",
      "------News-------\n",
      "                 pmi\n",
      "word                \n",
      "assignment  3.555348\n",
      "english     3.555348\n",
      "pharmacy    3.555348\n",
      "humanity    2.862201\n",
      "cheat       2.862201\n",
      "cheating    2.862201\n",
      "letter      2.456736\n",
      "skill       2.456736\n",
      "c           2.456736\n",
      "luck        2.456736\n",
      "------Other-------\n",
      "                  pmi\n",
      "word                 \n",
      "hamas        4.375757\n",
      "israel       4.375757\n",
      "vaccine      4.375757\n",
      "palestinian  4.375757\n",
      "pharmacy     3.970292\n",
      "genocide     3.970292\n",
      "roommate     3.682610\n",
      "protest      3.682610\n",
      "stem         3.459466\n",
      "mask         3.459466\n",
      "------Courses-------\n",
      "                  pmi\n",
      "word                 \n",
      "pharmacy     3.091042\n",
      "genocide     3.091042\n",
      "roommate     3.091042\n",
      "vaccine      3.091042\n",
      "toronto      3.091042\n",
      "hamas        3.091042\n",
      "white        3.091042\n",
      "palestinian  3.091042\n",
      "war          3.091042\n",
      "israel       3.091042\n",
      "------Academics-------\n",
      "                  pmi\n",
      "word                 \n",
      "palestinian  3.332205\n",
      "israel       3.332205\n",
      "vaccine      3.332205\n",
      "club         3.332205\n",
      "medium       3.332205\n",
      "building     3.332205\n",
      "canadian     3.332205\n",
      "hamas        3.332205\n",
      "genocide     3.332205\n",
      "art          2.639057\n",
      "------Advice-------\n",
      "                  pmi\n",
      "word                 \n",
      "hamas        3.091042\n",
      "palestinian  3.091042\n",
      "israel       3.091042\n",
      "protest      3.091042\n",
      "genocide     2.397895\n",
      "cheating     1.992430\n",
      "roommate     1.992430\n",
      "vaccine      1.992430\n",
      "member       1.992430\n",
      "cheat        1.992430\n",
      "------nan-------\n",
      "         pmi\n",
      "word        \n",
      "like    -inf\n",
      "heard   -inf\n",
      "system  -inf\n",
      "advice  -inf\n",
      "asked   -inf\n",
      "however -inf\n",
      "action  -inf\n",
      "midterm -inf\n",
      "drop    -inf\n",
      "covid   -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\toirt\\AppData\\Local\\Temp\\ipykernel_29624\\3500840323.py:24: RuntimeWarning: divide by zero encountered in log\n",
      "  pmi = np.log((pxy * n) / (px*py))\n"
     ]
    }
   ],
   "source": [
    "uoft_pmi = pd.concat([uoft_mi, vader_df[['is_neg', 'university_name']]], axis = 1)\n",
    "\n",
    "for flair in uoft_pmi['flair'].unique():\n",
    "    print(f'------{flair}-------')\n",
    "    print(calcpmi(uoft_pmi[uoft_pmi['flair'] == flair], uoft_500, 'negative', 'is_neg').sort_values(by = 'pmi', ascending= False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "59d86c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Discussion-------\n",
      "                pmi\n",
      "word               \n",
      "tipping    3.761200\n",
      "protest    3.068053\n",
      "cpen       2.913902\n",
      "rain       2.662588\n",
      "server     2.662588\n",
      "proctorio  2.557227\n",
      "driver     2.557227\n",
      "wolf       2.461917\n",
      "china      2.461917\n",
      "wage       2.374906\n",
      "------Humour-------\n",
      "                 pmi\n",
      "word                \n",
      "tipping     5.416100\n",
      "wolf        5.010635\n",
      "indigenous  4.722953\n",
      "restaurant  4.317488\n",
      "racism      4.317488\n",
      "police      4.317488\n",
      "protest     4.317488\n",
      "china       4.163337\n",
      "rain        4.163337\n",
      "wage        4.029806\n",
      "------News-------\n",
      "               pmi\n",
      "word              \n",
      "wolf      2.639057\n",
      "driver    2.639057\n",
      "culture   2.639057\n",
      "cpen      2.639057\n",
      "rain      2.639057\n",
      "computer  2.639057\n",
      "tipping   2.639057\n",
      "server    2.639057\n",
      "sleep     2.639057\n",
      "library   2.639057\n",
      "------nan-------\n",
      "           pmi\n",
      "word          \n",
      "people    -inf\n",
      "teaching  -inf\n",
      "worse     -inf\n",
      "exactly   -inf\n",
      "test      -inf\n",
      "joke      -inf\n",
      "lmao      -inf\n",
      "check     -inf\n",
      "im        -inf\n",
      "community -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\toirt\\AppData\\Local\\Temp\\ipykernel_29624\\3500840323.py:24: RuntimeWarning: divide by zero encountered in log\n",
      "  pmi = np.log((pxy * n) / (px*py))\n"
     ]
    }
   ],
   "source": [
    "ubc_pmi = pd.concat([ubc_mi, vader_df[['is_neg', 'university_name']]], axis = 1)\n",
    "\n",
    "for flair in ubc_pmi['flair'].unique():\n",
    "    print(f'------{flair}-------')\n",
    "    print(calcpmi(ubc_pmi[ubc_pmi['flair'] == flair], ubc_500, 'negative', 'is_neg').sort_values(by = 'pmi', ascending= False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "f37a04fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------HQ Post-------\n",
      "           pmi\n",
      "word          \n",
      "people    -inf\n",
      "teaching  -inf\n",
      "worse     -inf\n",
      "exactly   -inf\n",
      "test      -inf\n",
      "joke      -inf\n",
      "lmao      -inf\n",
      "check     -inf\n",
      "im        -inf\n",
      "community -inf\n",
      "------nan-------\n",
      "           pmi\n",
      "word          \n",
      "people    -inf\n",
      "teaching  -inf\n",
      "worse     -inf\n",
      "exactly   -inf\n",
      "test      -inf\n",
      "joke      -inf\n",
      "lmao      -inf\n",
      "check     -inf\n",
      "im        -inf\n",
      "community -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\toirt\\AppData\\Local\\Temp\\ipykernel_29624\\3500840323.py:24: RuntimeWarning: divide by zero encountered in log\n",
      "  pmi = np.log((pxy * n) / (px*py))\n",
      "C:\\Users\\toirt\\AppData\\Local\\Temp\\ipykernel_29624\\3500840323.py:24: RuntimeWarning: divide by zero encountered in log\n",
      "  pmi = np.log((pxy * n) / (px*py))\n"
     ]
    }
   ],
   "source": [
    "mcgill_pmi = pd.concat([mcgill_mi, vader_df[['is_neg', 'university_name']]], axis = 1)\n",
    "\n",
    "for flair in mcgill_pmi['flair'].unique():\n",
    "    print(f'------{flair}-------')\n",
    "    print(calcpmi(ubc_pmi[ubc_pmi['flair'] == flair], ubc_500, 'negative', 'is_neg').sort_values(by = 'pmi', ascending= False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b4ed8f",
   "metadata": {},
   "source": [
    "### Looking at comments level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "e8d60321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>title</th>\n",
       "      <th>date_created</th>\n",
       "      <th>university_name</th>\n",
       "      <th>flair</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>To the student who got caught using AI on their exam at U of T Law</td>\n",
       "      <td>2025-02-12 18:36:14</td>\n",
       "      <td>UofT</td>\n",
       "      <td>Transfers</td>\n",
       "      <td>Thanks a lot you dumb f*ck. Due to your idiocy and dumbassery my college (not in Ontario) is now...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It‚Äôs crazy that there‚Äôs people mad at YOU for venting.</td>\n",
       "      <td>To the student who got caught using AI on their exam at U of T Law</td>\n",
       "      <td>2025-02-12 18:36:14</td>\n",
       "      <td>UofT</td>\n",
       "      <td>Transfers</td>\n",
       "      <td>Thanks a lot you dumb f*ck. Due to your idiocy and dumbassery my college (not in Ontario) is now...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gaining access to your hard drives feels like a huge violation of privacy? I‚Äôm surprised that‚Äôs ...</td>\n",
       "      <td>To the student who got caught using AI on their exam at U of T Law</td>\n",
       "      <td>2025-02-12 18:36:14</td>\n",
       "      <td>UofT</td>\n",
       "      <td>Transfers</td>\n",
       "      <td>Thanks a lot you dumb f*ck. Due to your idiocy and dumbassery my college (not in Ontario) is now...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>?</td>\n",
       "      <td>To the student who got caught using AI on their exam at U of T Law</td>\n",
       "      <td>2025-02-12 18:36:14</td>\n",
       "      <td>UofT</td>\n",
       "      <td>Transfers</td>\n",
       "      <td>Thanks a lot you dumb f*ck. Due to your idiocy and dumbassery my college (not in Ontario) is now...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[removed]</td>\n",
       "      <td>To the student who got caught using AI on their exam at U of T Law</td>\n",
       "      <td>2025-02-12 18:36:14</td>\n",
       "      <td>UofT</td>\n",
       "      <td>Transfers</td>\n",
       "      <td>Thanks a lot you dumb f*ck. Due to your idiocy and dumbassery my college (not in Ontario) is now...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              comments  \\\n",
       "0                                                                                            [deleted]   \n",
       "1                                               It‚Äôs crazy that there‚Äôs people mad at YOU for venting.   \n",
       "2  Gaining access to your hard drives feels like a huge violation of privacy? I‚Äôm surprised that‚Äôs ...   \n",
       "3                                                                                                    ?   \n",
       "4                                                                                            [removed]   \n",
       "\n",
       "                                                                title  \\\n",
       "0  To the student who got caught using AI on their exam at U of T Law   \n",
       "1  To the student who got caught using AI on their exam at U of T Law   \n",
       "2  To the student who got caught using AI on their exam at U of T Law   \n",
       "3  To the student who got caught using AI on their exam at U of T Law   \n",
       "4  To the student who got caught using AI on their exam at U of T Law   \n",
       "\n",
       "          date_created university_name      flair  \\\n",
       "0  2025-02-12 18:36:14            UofT  Transfers   \n",
       "1  2025-02-12 18:36:14            UofT  Transfers   \n",
       "2  2025-02-12 18:36:14            UofT  Transfers   \n",
       "3  2025-02-12 18:36:14            UofT  Transfers   \n",
       "4  2025-02-12 18:36:14            UofT  Transfers   \n",
       "\n",
       "                                                                                           description  \n",
       "0  Thanks a lot you dumb f*ck. Due to your idiocy and dumbassery my college (not in Ontario) is now...  \n",
       "1  Thanks a lot you dumb f*ck. Due to your idiocy and dumbassery my college (not in Ontario) is now...  \n",
       "2  Thanks a lot you dumb f*ck. Due to your idiocy and dumbassery my college (not in Ontario) is now...  \n",
       "3  Thanks a lot you dumb f*ck. Due to your idiocy and dumbassery my college (not in Ontario) is now...  \n",
       "4  Thanks a lot you dumb f*ck. Due to your idiocy and dumbassery my college (not in Ontario) is now...  "
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_rows = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    for comment in eval(row['comments']):\n",
    "        comment_rows.append({\n",
    "            'comments': comment,\n",
    "            'title': row['title'],\n",
    "            'date_created': row['date_created'],\n",
    "            'university_name': row['university'],\n",
    "            'flair': row['flair'],\n",
    "            'description': row['description']\n",
    "        })\n",
    "\n",
    "comments_df = pd.DataFrame(comment_rows)\n",
    "comments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "f7ae59e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>title</th>\n",
       "      <th>date_created</th>\n",
       "      <th>university_name</th>\n",
       "      <th>flair</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>its crazy that theres people mad at you for venting</td>\n",
       "      <td>To the student who got caught using AI on their exam at U of T Law</td>\n",
       "      <td>2025-02-12 18:36:14</td>\n",
       "      <td>UofT</td>\n",
       "      <td>Transfers</td>\n",
       "      <td>Thanks a lot you dumb f*ck. Due to your idiocy and dumbassery my college (not in Ontario) is now...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gaining access to your hard drives feels like a huge violation of privacy im surprised thats eve...</td>\n",
       "      <td>To the student who got caught using AI on their exam at U of T Law</td>\n",
       "      <td>2025-02-12 18:36:14</td>\n",
       "      <td>UofT</td>\n",
       "      <td>Transfers</td>\n",
       "      <td>Thanks a lot you dumb f*ck. Due to your idiocy and dumbassery my college (not in Ontario) is now...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what canadian says college</td>\n",
       "      <td>To the student who got caught using AI on their exam at U of T Law</td>\n",
       "      <td>2025-02-12 18:36:14</td>\n",
       "      <td>UofT</td>\n",
       "      <td>Transfers</td>\n",
       "      <td>Thanks a lot you dumb f*ck. Due to your idiocy and dumbassery my college (not in Ontario) is now...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sighs sounds exhausting best of luck</td>\n",
       "      <td>To the student who got caught using AI on their exam at U of T Law</td>\n",
       "      <td>2025-02-12 18:36:14</td>\n",
       "      <td>UofT</td>\n",
       "      <td>Transfers</td>\n",
       "      <td>Thanks a lot you dumb f*ck. Due to your idiocy and dumbassery my college (not in Ontario) is now...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oof i only use ai for helping me understand concepts and actually backing up what it says with s...</td>\n",
       "      <td>To the student who got caught using AI on their exam at U of T Law</td>\n",
       "      <td>2025-02-12 18:36:14</td>\n",
       "      <td>UofT</td>\n",
       "      <td>Transfers</td>\n",
       "      <td>Thanks a lot you dumb f*ck. Due to your idiocy and dumbassery my college (not in Ontario) is now...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              comments  \\\n",
       "0                                                  its crazy that theres people mad at you for venting   \n",
       "1  gaining access to your hard drives feels like a huge violation of privacy im surprised thats eve...   \n",
       "2                                                                           what canadian says college   \n",
       "3                                                                 sighs sounds exhausting best of luck   \n",
       "4  oof i only use ai for helping me understand concepts and actually backing up what it says with s...   \n",
       "\n",
       "                                                                title  \\\n",
       "0  To the student who got caught using AI on their exam at U of T Law   \n",
       "1  To the student who got caught using AI on their exam at U of T Law   \n",
       "2  To the student who got caught using AI on their exam at U of T Law   \n",
       "3  To the student who got caught using AI on their exam at U of T Law   \n",
       "4  To the student who got caught using AI on their exam at U of T Law   \n",
       "\n",
       "          date_created university_name      flair  \\\n",
       "0  2025-02-12 18:36:14            UofT  Transfers   \n",
       "1  2025-02-12 18:36:14            UofT  Transfers   \n",
       "2  2025-02-12 18:36:14            UofT  Transfers   \n",
       "3  2025-02-12 18:36:14            UofT  Transfers   \n",
       "4  2025-02-12 18:36:14            UofT  Transfers   \n",
       "\n",
       "                                                                                           description  \n",
       "0  Thanks a lot you dumb f*ck. Due to your idiocy and dumbassery my college (not in Ontario) is now...  \n",
       "1  Thanks a lot you dumb f*ck. Due to your idiocy and dumbassery my college (not in Ontario) is now...  \n",
       "2  Thanks a lot you dumb f*ck. Due to your idiocy and dumbassery my college (not in Ontario) is now...  \n",
       "3  Thanks a lot you dumb f*ck. Due to your idiocy and dumbassery my college (not in Ontario) is now...  \n",
       "4  Thanks a lot you dumb f*ck. Due to your idiocy and dumbassery my college (not in Ontario) is now...  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_comments(text): \n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'\\n', ' ', text)            # Remove newlines\n",
    "    text = re.sub(r'http\\S+', '', text)        # Remove links\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)       # Remove punctuation/numbers\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "comments_df['comments'] = comments_df['comments'].apply(clean_comments)\n",
    "comments_df['comments'] = comments_df['comments'].str.strip()\n",
    "comments_df = comments_df[~comments_df['comments'].isin(['deleted', 'removed', ''])]\n",
    "comments_df = comments_df.reset_index(drop=True)\n",
    "comments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "80dadecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_lemmatize(text): \n",
    "        # Tokenize\n",
    "        tokens = word_tokenize(text)\n",
    "\n",
    "        # Filter for strings\n",
    "        words = [word for word in tokens if word.isalpha()]\n",
    "\n",
    "        # Remove stopwords\n",
    "        words = [word for word in words if word not in stop_words]\n",
    "        \n",
    "        # Lemmatize\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        return [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "comments_df['lemmatized_tokens'] = comments_df['comments'].apply(tokenize_and_lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "f18640a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                        [crazy, there, people, mad, venting]\n",
       "1         [gaining, access, hard, drive, feel, like, huge, violation, privacy, im, surprised, thats, even,...\n",
       "2                                                                                    [canadian, say, college]\n",
       "3                                                                       [sigh, sound, exhausting, best, luck]\n",
       "4         [oof, use, ai, helping, understand, concept, actually, backing, say, source, idk, many, ppl, use...\n",
       "                                                         ...                                                 \n",
       "110420    [new, course, catalogue, awful, lacking, ability, see, course, subject, unreal, thanks, good, wo...\n",
       "110421                                     [think, lot, people, agree, old, system, worked, better, honestly]\n",
       "110422                                                                [incoming, student, life, saver, thank]\n",
       "110423                                        [dont, want, change, minerva, whatever, replaced, would, worse]\n",
       "110424                                                                   [plan, removing, older, review, etc]\n",
       "Name: lemmatized_tokens, Length: 110425, dtype: object"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df['lemmatized_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "a7e5c0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "complaint_keywords = [\n",
    "    'hate', 'bad', 'terrible', 'worst', 'awful', 'complain', 'issue', \n",
    "    'problem', 'suck', 'annoy', 'disappoint', 'frustrate', 'dumb', \n",
    "    'incompetent', 'bureaucracy', 'useless', 'slow', 'broken'\n",
    "]\n",
    "\n",
    "def is_complaint(tokens):\n",
    "    return any(token in complaint_keywords for token in tokens)\n",
    "\n",
    "comments_df['is_complaint'] = comments_df['lemmatized_tokens'].apply(is_complaint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "dfae4a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "complaint_keywords = ['course', 'class', 'test', 'prof', 'professor', 'exam']\n",
    "\n",
    "def is_complaint(tokens):\n",
    "    return any(token in complaint_keywords for token in tokens)\n",
    "\n",
    "comments_df['is_complaint'] = comments_df['lemmatized_tokens'].apply(is_complaint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "6b4c113b",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_vader = evalsentences(comments_df['comments'], comments_df['university_name'], to_df = True, columns = ['comments', 'vader', 'university_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "4d370676",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df['vader'] = comments_vader['vader']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "6d461789",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df['joined_text'] = comments_df['lemmatized_tokens'].apply(lambda tokens: ' '.join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "74b67c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # Adjust max_features as needed\n",
    "X = vectorizer.fit_transform(comments_df['joined_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf4583f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['comments', 'title', 'date_created', 'university_name', 'flair',\n",
       "       'description', 'lemmatized_tokens', 'is_complaint', 'vader',\n",
       "       'joined_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "3babcfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df.sample(n=1000, random_state=42).to_csv('labelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "e0391e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<110425x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1301198 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "e5637fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "uoft_comments = comments_df[comments_df['university_name'] == 'UofT'].reset_index(drop=True)\n",
    "ubc_comments = comments_df[comments_df['university_name'] == 'UBC'].reset_index(drop=True)\n",
    "mcgill_comments = comments_df[comments_df['university_name'] == 'McGill'].reset_index(drop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
